{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPS (dictionaries)\n",
    "\n",
    "defined by a 'key:value' structure\n",
    "- set based data structure\n",
    "(note: an array is a list based structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sets\n",
    "comparable to a list\n",
    "sets dont have an order\n",
    "however they dont have duplicates\n",
    "\n",
    "- a group of keys is a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'u': 1, 'd': 2, 'a': 3, 'c': 4, 'i': 5, 't': 6, 'y': 7}\n"
     ]
    }
   ],
   "source": [
    "udacity = {}\n",
    "udacity['u'] = 1\n",
    "udacity['d'] = 2\n",
    "udacity['a'] = 3\n",
    "udacity['c'] = 4\n",
    "udacity['i'] = 5\n",
    "udacity['t'] = 6\n",
    "udacity['y'] = 7\n",
    "\n",
    "print (udacity)\n",
    "# {'u': 1, 'd': 2, 'a': 3, 'c': 4, 'i': 5, 't': 6, 'y': 7}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries are wonderfully flexibleâ€”you can store a wide variety of structures as values. You store another dictionary or a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'North America': {'USA': ['Mountain View', 'Atlanta']}, 'Asia': {'India': ['Bangalore', 'New Delhi'], 'China': ['Shanghai']}, 'Africa': {'Egypt': ['Cairo']}}\n",
      "1\n",
      "Atlanta\n",
      "Mountain View\n",
      "2\n",
      "Bangalore - India\n",
      "New Delhi - India\n",
      "Shanghai - China\n"
     ]
    }
   ],
   "source": [
    "locations = {'North America': {'USA': ['Mountain View']}}\n",
    "locations['North America']['USA'].append('Atlanta')\n",
    "locations['Asia'] = {'India': ['Bangalore']}\n",
    "locations['Asia']['India'].append('New Delhi')\n",
    "locations['Asia']['China'] = ['Shanghai']\n",
    "locations['Africa'] = {'Egypt': ['Cairo']}\n",
    "print (locations)\n",
    "\n",
    "# TODO: Print a list of all cities in the USA in alphabetic order.\n",
    "print (1)\n",
    "usa_sorted = sorted(locations['North America']['USA'])\n",
    "for city in usa_sorted:\n",
    "    print (city)\n",
    "# TODO: Print all cities in Asia, in alphabetic order, next to the name of the country\n",
    "print (2)\n",
    "asia_cities = []\n",
    "for country, cities in locations['Asia'].items():\n",
    "    for city in cities:\n",
    "        asia_cities.append('{} - {}'.format(city, country))\n",
    "asia_sorted = sorted(asia_cities)\n",
    "for city in asia_sorted:\n",
    "    print (city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing\n",
    "transform value to a hash value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collisions\n",
    "two hashes having the same remainder or look up value\n",
    "### Normal Array vs. Bucket\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash Maps\n",
    "Create a hash table to show that you understand hashing\n",
    "Try to shoot for constant time lookups with hashing\n",
    "store a key and value in a hash table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two popular ways in which we handle collisions.\n",
    "\n",
    "Separate chaining - Separate chaining is a clever technique where we use the same bucket to store multiple objects. The bucket in this case will store a linked list of key-value pairs. Every bucket has it's own separate chain of linked list nodes.\n",
    "Open Addressing - In open addressing, we do the following:\n",
    "\n",
    "If, after getting the bucket index, the bucket is empty, we store the object in that particular bucket\n",
    "\n",
    "If the bucket is not empty, we find an alternate bucket index by using another function which modifies the current hash code to give a new code. This process of finding an alternate bucket index is called probing. A few probing techniques are - linear probing, qudratic probing, or double hashing.\n",
    "\n",
    "Separate chaining is a simple and effective technique to handle collisions and that is what we discuss here. Let us visualize the new bucket array one more time as shown in the figure below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkedListNode:\n",
    "    \n",
    "    def __init__(self, key, value):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.next = None\n",
    "\n",
    "class HashMap:\n",
    "    \n",
    "    def __init__(self, initial_size = 15):\n",
    "        self.bucket_array = [None for _ in range(initial_size)]\n",
    "        self.p = 31\n",
    "        self.num_entries = 0\n",
    "        self.load_factor = 0.7\n",
    "        \n",
    "    def put(self, key, value):\n",
    "        bucket_index = self.get_bucket_index(key)\n",
    "\n",
    "        new_node = LinkedListNode(key, value)\n",
    "        head = self.bucket_array[bucket_index]\n",
    "\n",
    "        # check if key is already present in the map, and update it's value\n",
    "        while head is not None:\n",
    "            if head.key == key:\n",
    "                head.value = value\n",
    "                return\n",
    "            head = head.next\n",
    "\n",
    "        # key not found in the chain --> create a new entry and place it at the head of the chain\n",
    "        head = self.bucket_array[bucket_index]\n",
    "        new_node.next = head\n",
    "        self.bucket_array[bucket_index] = new_node\n",
    "        self.num_entries += 1\n",
    "        \n",
    "        # check for load factor\n",
    "        current_load_factor = self.num_entries / len(self.bucket_array)\n",
    "        if current_load_factor > self.load_factor:\n",
    "            self.num_entries = 0\n",
    "            self._rehash()\n",
    "        \n",
    "    def get(self, key):\n",
    "        bucket_index = self.get_hash_code(key)\n",
    "        head = self.bucket_array[bucket_index]\n",
    "        while head is not None:\n",
    "            if head.key == key:\n",
    "                return head.value\n",
    "            head = head.next\n",
    "        return None\n",
    "        \n",
    "    def get_bucket_index(self, key):\n",
    "        bucket_index = self.get_hash_code(key)\n",
    "        return bucket_index\n",
    "    \n",
    "    def get_hash_code(self, key):\n",
    "        key = str(key)\n",
    "        num_buckets = len(self.bucket_array)\n",
    "        current_coefficient = 1\n",
    "        hash_code = 0\n",
    "        for character in key:\n",
    "            hash_code += ord(character) * current_coefficient\n",
    "            hash_code = hash_code % num_buckets                       # compress hash_code\n",
    "            current_coefficient *= self.p\n",
    "            current_coefficient = current_coefficient % num_buckets   # compress coefficient\n",
    "        return hash_code % num_buckets                                # one last compression before returning\n",
    "    \n",
    "    def size(self):\n",
    "        return self.num_entries\n",
    "\n",
    "    def _rehash(self):\n",
    "        old_num_buckets = len(self.bucket_array)\n",
    "        old_bucket_array = self.bucket_array\n",
    "        num_buckets = 2 * old_num_buckets\n",
    "        self.bucket_array = [None for _ in range(num_buckets)]\n",
    "\n",
    "        for head in old_bucket_array:\n",
    "            while head is not None:\n",
    "                key = head.key\n",
    "                value = head.value\n",
    "                self.put(key, value)         # we can use our put() method to rehash\n",
    "                head = head.next\n",
    "                \n",
    "    def delete(self, key):\n",
    "        bucket_index = self.get_bucket_index(key)\n",
    "        head = self.bucket_array[bucket_index]\n",
    "\n",
    "        previous = None\n",
    "        while head is not None:\n",
    "            if head.key == key:\n",
    "                if previous is None:\n",
    "                    self.bucket_array[bucket_index] = head.next\n",
    "                else:\n",
    "                    previous.next = head.next\n",
    "                self.num_entries -= 1\n",
    "                return\n",
    "            else:\n",
    "                previous = head\n",
    "                head = head.next\n",
    "\n",
    "    \n",
    "    # Helper function to see the hashmap\n",
    "    def __repr__(self):\n",
    "        output = \"\\nLet's view the hash map:\"\n",
    "\n",
    "        node = self.bucket_array\n",
    "        for bucket_index, node in enumerate(self.bucket_array):\n",
    "            if node is None:\n",
    "                output += '\\n[{}] '.format(bucket_index)\n",
    "            else:\n",
    "                output += '\\n[{}]'.format(bucket_index)\n",
    "                while node is not None:\n",
    "                    output += ' ({} , {}) '.format(node.key, node.value)\n",
    "                    if node.next is not None:\n",
    "                        output += ' --> '\n",
    "                    node = node.next\n",
    "                    \n",
    "        return output\n",
    "\n",
    "\n",
    "# Test delete operation\n",
    "hash_map = HashMap(7)\n",
    "\n",
    "hash_map.put(\"one\", 1)\n",
    "hash_map.put(\"two\", 2)\n",
    "hash_map.put(\"three\", 3)\n",
    "hash_map.put(\"neo\", 11)\n",
    "\n",
    "print(\"size: {}\".format(hash_map.size()))\n",
    "\n",
    "\n",
    "print(\"one: {}\".format(hash_map.get(\"one\")))\n",
    "print(\"neo: {}\".format(hash_map.get(\"neo\")))\n",
    "print(\"three: {}\".format(hash_map.get(\"three\")))\n",
    "print(\"size: {}\".format(hash_map.size()))\n",
    "hash_map                          # call to the helper function to see the hashmap\n",
    "\n",
    "\n",
    "hash_map.delete(\"one\")\n",
    "hash_map                          # call to the helper function to see the hashmap\n",
    "\n",
    "print(hash_map.get(\"one\"))\n",
    "print(hash_map.size())\n",
    "\n",
    "\n",
    "# Test Rehashing\n",
    "\n",
    "# We have reduced the size of the hashmap array to increase the load factor (> 0.7) \n",
    "# and hence trigger the rehash() function\n",
    "hash_map = HashMap(5)                        \n",
    "\n",
    "hash_map.put(\"one\", 1)\n",
    "hash_map.put(\"two\", 2)\n",
    "hash_map.put(\"three\", 3)\n",
    "hash_map.put(\"neo\", 11)\n",
    "\n",
    "print(\"size: {}\".format(hash_map.size()))\n",
    "\n",
    "\n",
    "print(\"one: {}\".format(hash_map.get(\"one\")))\n",
    "print(\"neo: {}\".format(hash_map.get(\"neo\")))\n",
    "print(\"three: {}\".format(hash_map.get(\"three\")))\n",
    "print(\"size: {}\".format(hash_map.size()))\n",
    "\n",
    "hash_map                          # call to the helper function to see the hashmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Keys\n",
    "getting ASCII values to create hash values\n",
    "\"UD\" U = 85, d = 68\n",
    "(85 * 31^1) + 68 = 2703"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching\n",
    "Storing data into a temporary data storage to avoid recomputation or to avoid reading the data from a relatively slower part of memory again and again\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Stair case problem but with caching\n",
    "def staircase(n):\n",
    "    \n",
    "    # start with a blank dictionary. It will populate in the recursive call\n",
    "    num_dict = dict({})           \n",
    "    return staircase_faster(n, num_dict)\n",
    "\n",
    "\n",
    "'''Recursice function'''\n",
    "def staircase_faster(n, num_dict):\n",
    "    ''' \n",
    "    Here `n` is a key and `output` would be the corresponding value \n",
    "    to be inserted into the dictionary as a pair\n",
    "    '''\n",
    "    \n",
    "    # Base cases\n",
    "    if n == 1:\n",
    "        output = 1\n",
    "    elif n == 2:\n",
    "        output = 2\n",
    "    elif n == 3:\n",
    "        output = 4\n",
    "    else:\n",
    "        \n",
    "        # Simply check if the \"value\" corresponding to \"(n-1)\" key is already available in the dictionary\n",
    "        if (n - 1) in num_dict:\n",
    "            first_output = num_dict[n - 1]\n",
    "\n",
    "        # Otherwise, calculate and insert the new key-value pair into the dictioanry\n",
    "        else:\n",
    "            first_output =  staircase_faster(n - 1, num_dict)\n",
    "        \n",
    "        if (n - 2) in num_dict:\n",
    "            second_output = num_dict[n - 2]\n",
    "        else:\n",
    "            second_output = staircase_faster(n - 2, num_dict)\n",
    "            \n",
    "        if (n - 3) in num_dict:\n",
    "            third_output = num_dict[n - 3]\n",
    "        else:\n",
    "            third_output = staircase_faster(n - 3, num_dict)\n",
    "        \n",
    "        output = first_output + second_output + third_output\n",
    "    \n",
    "    num_dict[n] = output;   # insert a key-value pair in the ORIGINAL dictionary \n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pair_sum_to_target(input_list, target):\n",
    "    pairs = {}\n",
    "    for i, num in enumerate(input_list):\n",
    "        if target - num in pairs:\n",
    "            return [pairs[target-num], i]\n",
    "        pairs[num] = i\n",
    "        \n",
    "    return []\n",
    "\n",
    "\n",
    "\n",
    "input_list = [1, 5, 9, 7]\n",
    "target = 8\n",
    "pair_sum_to_target(input_list, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_consecutive_subsequence(input_list):\n",
    "    \n",
    "    # Create a dictionary.\n",
    "    # Each element of the input_list would become a \"key\", and\n",
    "    # the corresponding index in the input_list would become the \"value\"\n",
    "    element_dict = dict()\n",
    "\n",
    "    # Traverse through the input_list, and populate the dictionary\n",
    "    # Time complexity = O(n) \n",
    "    for index, element in enumerate(input_list):\n",
    "        element_dict[element] = index\n",
    "\n",
    "    # Represents the length of longest subsequence\n",
    "    max_length = -1\n",
    "    \n",
    "    # Represents the index of smallest element in the longest subsequence\n",
    "    starts_at = -1  \n",
    "\n",
    "    # Traverse again - Time complexity = O(n) \n",
    "    for index, element in enumerate(input_list):\n",
    "\n",
    "        current_starts = index\n",
    "        element_dict[element] = -1         # Mark as visited\n",
    "\n",
    "        current_count = 1                  # length of the current subsequence\n",
    "\n",
    "        '''CHECK ONE ELEMENT FORWARD'''\n",
    "        current = element + 1              # `current` is the expected number\n",
    "\n",
    "        # check if the expected number is available (as a key) in the dictionary,\n",
    "        # and it has not been visited yet (i.e., value > 0)\n",
    "        # Time complexity: Constant time for checking a key and retrieving the value = O(1)\n",
    "        while current in element_dict and element_dict[current] > 0:\n",
    "            current_count += 1             # increment the length of subsequence \n",
    "            element_dict[current] = -1     # Mark as visited\n",
    "            current = current + 1          \n",
    "\n",
    "            \n",
    "        '''CHECK ONE ELEMENT BACKWARD'''\n",
    "        # Time complexity: Constant time for checking a key and retrieving the value = O(1)\n",
    "        current = element - 1             # `current` is the expected number\n",
    "\n",
    "        while current in element_dict and element_dict[current] > 0:    \n",
    "            current_starts = element_dict[current]         # index of smallest element in the current subsequence\n",
    "            current_count += 1                             # increment the length of subsequence \n",
    "            element_dict[current] = -1\n",
    "            current = current - 1\n",
    "\n",
    "        '''If length of current subsequence >= max length of previously visited subsequence'''\n",
    "        if current_count >= max_length:\n",
    "            if current_count == max_length and current_starts > starts_at:\n",
    "                continue\n",
    "            starts_at = current_starts            # index of smallest element in the current (longest so far) subsequence\n",
    "            max_length = current_count            # store the length of current (longest so far) subsequence\n",
    "\n",
    "\n",
    "    start_element = input_list[starts_at]          # smallest element in the longest subsequence\n",
    "\n",
    "    # return a NEW list starting from `start_element` to `(start_element + max_length)` \n",
    "    return [element for element in range(start_element, start_element + max_length)]\n",
    "\n",
    "test_case_1 = [[5, 4, 7, 10, 1, 3, 55, 2], [1, 2, 3, 4, 5]]\n",
    "test_function(test_case_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
